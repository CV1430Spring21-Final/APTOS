{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Diabetic Retina Pathology \n",
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.19.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.2.4)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## GPU Configuration: \n",
    "#### If Training on a GPU enabled machine, use the following imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "#     tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resized_train_cropped']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"resized_train_cropped/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (512, 512)\n",
    "BATCH_SIZE = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "path = \"resized_train_cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in total -  1285\n"
     ]
    }
   ],
   "source": [
    "data = \"resized_train_cropped/resized_train_cropped/\"\n",
    "print('number of images in total - ',len(os.listdir(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"/home/jupyter/deployed_notebook/retina_741_data/trainLabels_cropped.csv\") \n",
    "print('number of images in total - ',len(data_frame))\n",
    "data_frame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intepretation of the data listed above: \n",
    "You are provided with a large set of high-resolution retina images taken under a variety of imaging conditions. A left and right field is provided for every subject. Images are labeled with a subject id as well as either left or right (e.g. 1_left.jpeg is the left eye of patient id 1).\n",
    "\n",
    "A clinician has rated the presence of diabetic retinopathy in each image on a scale of 0 to 4, according to the following scale:\n",
    "\n",
    "0 - No DR\n",
    "\n",
    "1 - Mild\n",
    "\n",
    "2 - Moderate\n",
    "\n",
    "3 - Severe\n",
    "\n",
    "4 - Proliferative DR\n",
    "\n",
    "### Pre-processing and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# If the patient has the retinopathy or not:\n",
    "data_frame['retinopathy'] = data_frame['level'].map(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "#Which eye is the patient having pathology: \n",
    "data_frame['right_eye'] = data_frame['image'].map(lambda x: 1 if x.split('_')[-1] == 'right' else 0)\n",
    "data_frame['image_name'] = [i+\".jpeg\" for i in data_frame['image'].values]\n",
    "\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "data_frame = pd.concat([data_frame,pd.get_dummies(data_frame['level'], prefix='severity:')],axis=1)\n",
    "\n",
    "#TODO: Change the following: \n",
    "data_frame['path'] = data_frame['image'].map(lambda x: os.path.join('/home/jupyter/deployed_notebook/retina_741_data/resized_train_cropped/resized_train_cropped/',\n",
    "                                                         '{}.jpeg'.format(x)))\n",
    "#TODO: Change the following: \n",
    "pruned_data = data_frame[['path', 'severity:_0','severity:_1','severity:_2','severity:_3','severity:_4','image_name','retinopathy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "pruned_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "np.random.choice(pruned_data['image_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a random sample from the input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "rand_sample = np.random.choice(pruned_data['image_name'])\n",
    "temp = os.path.join(path, rand_sample)\n",
    "\n",
    "plt.imshow(plt.imread(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand_sample = np.random.choice(pruned_data['image_name'])\n",
    "temp = os.path.join(path, rand_sample)\n",
    "\n",
    "plt.imshow(plt.imread(temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific layout for retinopathy and left/right eyes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "pruned_data[['retinopathy', 'severity:_0','severity:_1','severity:_2','severity:_3','severity:_4']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# train1, val = train_test_split(index, test_size=0.2)\n",
    "# train, test = train_test_split(train1, test_size=0.25)\n",
    "\n",
    "#80/20/20 split\n",
    "\n",
    "train1_ids, valid_ids = train_test_split(pruned_data,test_size = 0.2)\n",
    "train_and_test = pruned_data[pruned_data.isin(train1_ids)]\n",
    "\n",
    "train_ids, test_ids = train_test_split(train_and_test,test_size = 0.25)\n",
    "\n",
    "train_set =train_ids.dropna()\n",
    "\n",
    "valid_set = valid_ids.dropna()\n",
    "test_set = test_ids.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {},
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_set.shape, test_set.shape, valid_set.shape)\n",
    "print(type(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# train_x = train_set.drop('level', axis=1)\n",
    "# train_y = train_set['level']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Generation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16,InceptionResNetV2,InceptionV3 as pretrained_model\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def calc_mean_and_std(img_directory_list):\n",
    "        \"\"\" Calculate mean and standard deviation of a sample of the\n",
    "        training dataset for standardization.\n",
    "\n",
    "        Arguments: none\n",
    "\n",
    "        Returns: none\n",
    "        \"\"\"\n",
    "        PREPROCESS_SAMPLE_SIZE = 24\n",
    "        IMG_LENGTH_HEIGHT = 512\n",
    "         \n",
    "        # Get list of all images in training directory\n",
    "        file_list = np.copy(img_directory_list)\n",
    "\n",
    "\n",
    "        # Shuffle filepaths\n",
    "        random.shuffle(file_list)\n",
    "\n",
    "        # Take sample of file paths\n",
    "        file_list = file_list[:PREPROCESS_SAMPLE_SIZE]\n",
    "\n",
    "        # Allocate space in memory for images\n",
    "        data_sample = np.zeros(\n",
    "            (PREPROCESS_SAMPLE_SIZE,IMG_LENGTH_HEIGHT, IMG_LENGTH_HEIGHT, 3))\n",
    "\n",
    "        # Import images\n",
    "        for i, file_path in enumerate(file_list):\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((IMG_LENGTH_HEIGHT, IMG_LENGTH_HEIGHT))\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "#             img /= 255.\n",
    "\n",
    "            # Grayscale -> RGB\n",
    "            if len(img.shape) == 2:\n",
    "                img = np.stack([img, img, img], axis=-1)\n",
    "\n",
    "            data_sample[i] = img\n",
    "\n",
    "        # TODO: Calculate the pixel-wise mean and standard deviation\n",
    "        #       of the images in data_sample and store them in\n",
    "        #       self.mean and self.std respectively.\n",
    "        # ==========================================================\n",
    "\n",
    "        mean = np.mean(data_sample, axis=(0, 1, 2))\n",
    "        std = np.std(data_sample, axis=(0, 1, 2))\n",
    "\n",
    "        # ==========================================================\n",
    "\n",
    "        print(\"Dataset mean: [{0:.4f}, {1:.4f}, {2:.4f}]\".format(\n",
    "            mean[0], mean[1], mean[2]))\n",
    "\n",
    "        print(\"Dataset std: [{0:.4f}, {1:.4f}, {2:.4f}]\".format(\n",
    "            std[0], std[1], std[2]))\n",
    "        \n",
    "        return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "train_set_mean, train_set_std = calc_mean_and_std(train_set['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def train_img_preprocess_fn(img):\n",
    "    img = tf.keras.applications.vgg16.preprocess_input(img)\n",
    "#     img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "#     img = tf.keras.applications.inception_resnet_v2.preprocess_input(img)\n",
    "#     img = img / 255\n",
    "#     print(img)\n",
    "    for layer in range(img.shape[2]):\n",
    "            img[:,:,layer] = (img[:,:,layer] - train_set_mean[layer]) / train_set_std[layer]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_processed_data(data_frame):\n",
    "  \n",
    "    data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#                     featurewise_center=True,\n",
    "#                     featurewise_std_normalization=True,\n",
    "#                     zca_whitening = True, \n",
    "                    rotation_range=20,\n",
    "                    width_shift_range=5,\n",
    "                    height_shift_range=5,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip = True, \n",
    "#                     preprocessing_function=train_img_preprocess_fn\n",
    "    )\n",
    "    \n",
    "    # Form image data generator from directory structure\n",
    "#     data_gen = data_gen.flow_from_directory(\n",
    "#         path,\n",
    "#         target_size=IMG_SIZE,\n",
    "#         class_mode='sparse',\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         classes=classes_for_flow)\n",
    "    data_gen = data_gen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        directory=None,\n",
    "        x_col=\"path\",\n",
    "        y_col=['severity:_0','severity:_1','severity:_2','severity:_3','severity:_4'],\n",
    "        weight_col=None,\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        validate_filenames=False,\n",
    "    )\n",
    "    \n",
    "    return data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def get_unprocessed_data(data_frame):\n",
    "\n",
    "\n",
    "    data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#                     featurewise_center=True,\n",
    "#                     featurewise_std_normalization=True,\n",
    "#                     rotation_range=20,\n",
    "#                     width_shift_range=0.2,\n",
    "#                     height_shift_range=0.2,\n",
    "#                     shear_range=0.2,\n",
    "#                     zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip = True, \n",
    "#                     preprocessing_function=img_preprocess_fn\n",
    "    )\n",
    "    \n",
    "    # Form image data generator from directory structure\n",
    "#     data_gen = data_gen.flow_from_directory(\n",
    "#         path,\n",
    "#         target_size=IMG_SIZE,\n",
    "#         class_mode='sparse',\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         classes=classes_for_flow)\n",
    "    data_gen = data_gen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        directory=None,\n",
    "        x_col=\"path\",\n",
    "        y_col=['severity:_0','severity:_1','severity:_2','severity:_3','severity:_4'],\n",
    "        weight_col=None,\n",
    "        target_size=IMG_SIZE,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        validate_filenames=False,\n",
    "    )\n",
    "    \n",
    "    return data_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "gen_train_set = get_processed_data(train_set)\n",
    "print(gen_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "retina_data, retina_sev = next(gen_train_set)\n",
    "    \n",
    "figure, plot_axs = plt.subplots(4, 8, figsize = (16, 8))\n",
    "\n",
    "\n",
    "for (data, sev, subplt) in zip(retina_data, retina_sev, plot_axs.flatten()):\n",
    "    clipped = np.clip(data, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    subplt.imshow(clipped)\n",
    "    subplt.set_title('Retinopathy: {}'.format(np.argmax(sev, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "gen_valid_set = get_unprocessed_data(valid_set)\n",
    "print(gen_valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "retina_data, retina_sev = next(gen_valid_set)\n",
    "    \n",
    "figure, plot_axs = plt.subplots(4, 8, figsize = (16, 8))\n",
    "\n",
    "\n",
    "for (data, sev, subplt) in zip(retina_data, retina_sev, plot_axs.flatten()):\n",
    "    clipped = np.clip(data, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    subplt.imshow(clipped)\n",
    "    subplt.set_title('Retinopathy: {}'.format(np.argmax(sev, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "#### Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "gen_test_set = get_unprocessed_data(test_set)\n",
    "print(gen_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "retina_data, retina_sev = next(gen_valid_set)\n",
    "    \n",
    "figure, plot_axs = plt.subplots(4, 8, figsize = (16, 8))\n",
    "\n",
    "\n",
    "for (data, sev, subplt) in zip(retina_data, retina_sev, plot_axs.flatten()):\n",
    "    clipped = np.clip(data, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    subplt.imshow(clipped)\n",
    "    subplt.set_title('Retinopathy: {}'.format(np.argmax(sev, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#type(t_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout,LocallyConnected2D, MaxPool2D, Flatten, Input, Conv2D, multiply, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "input_layer = Input(t_x.shape[1:])\n",
    "base_pretrained_model = pretrained_model(input_shape =  t_x.shape[1:], include_top = False, weights = 'imagenet')\n",
    "\n",
    "base_pretrained_model.trainable = False\n",
    "base_pretrained_model.summary()\n",
    "base_pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_imagenet = base_pretrained_model(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_normalization_layer = BatchNormalization()(after_imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_normalization_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_head = None\n",
    "weight_matrix = np.ones((1, 1, 1, pt_depth))\n",
    "\n",
    "\n",
    "                 \n",
    "out_custom_head = Conv2D(512, 3, 1, padding=\"same\", activation=\"relu\", name=\"trainable1_head_1\",)(batch_normalization_layer)\n",
    "out_custom_head = Conv2D(256, 3, 1, padding=\"same\", activation=\"relu\", name=\"trainable1_head_2\")(out_custom_head)\n",
    "out_custom_head = Conv2D(128, 3, 1, padding=\"same\", activation=\"relu\", name=\"trainable1_head_3\")(out_custom_head)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_head = Conv2D(64, 3, 1, padding=\"same\", activation=\"relu\", name=\"trainable2_head_1\")(out_custom_head)\n",
    "out_custom_head = GlobalAveragePooling2D()(out_custom_head)\n",
    "\n",
    "out_custom_head=Dense(128,activation='softmax')(out_custom_head)\n",
    "out_custom_head=Dense(5,activation='softmax')(out_custom_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_model = tf.keras.models.Model(inputs = [input_layer], outputs = [out_custom_head])\n",
    "retina_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "                           metrics = ['categorical_accuracy', top_2_accuracy])\n",
    "\n",
    "retina_model.summary()\n",
    "\n",
    "inceptionv3 \n",
    "\n",
    "head                   globalpollinglayer \n",
    "\n",
    " Layer \n",
    "Dense Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output after ImageNet Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def top_2_accuracy(in_gt, in_pred):\n",
    "    return top_k_categorical_accuracy(in_gt, in_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now()\n",
    "timestamp = time_now.strftime(\"%m%d%y-%H%M%S\")\n",
    "checkpoint_path = \"checkpoints\" + os.sep + \"your_model\" + os.sep + timestamp + os.sep\n",
    "logs_path = \"logs\" + os.sep + \"your_model\" + os.sep + timestamp + os.sep\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='auto', save_weights_only = True,save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "439/439 [==============================] - 1446s 3s/step - loss: 1.3079 - categorical_accuracy: 0.7236 - top_2_accuracy: 0.8850 - val_loss: 0.9910 - val_categorical_accuracy: 0.7343 - val_top_2_accuracy: 0.8871\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99102, saving model to checkpoints/your_model/042121-024902/\n",
      "Epoch 2/4\n",
      " 12/439 [..............................] - ETA: 20:28 - loss: 0.9194 - categorical_accuracy: 0.7811 - top_2_accuracy: 0.9166"
     ]
    }
   ],
   "source": [
    "model_train = retina_model.fit(gen_train_set, \n",
    "                           steps_per_epoch = np.array(train_set.shape[0]//BATCH_SIZE),\n",
    "                           validation_data = gen_valid_set, \n",
    "                           validation_steps = valid_set.shape[0]//BATCH_SIZE,\n",
    "                              epochs = 4, \n",
    "                              callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "!rm -rf ~/.keras # clean up before starting training\n",
    "!rm -rf ~/.local/share/Trash/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown 1000:1001 /opt/conda/pkgs/cache/18414ddb.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best version of the model\n",
    "retina_model.load_weights(weight_path)\n",
    "retina_model.save('full_retina_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if it's first time running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "retina_model.save('full_retina_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if loading from the machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retina_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-615cd55c55c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretina_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_model_inceptionv3_0421_2021.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'retina_model' is not defined"
     ]
    }
   ],
   "source": [
    "retina_model.load('full_model_inceptionv3_0421_2021.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#plt.plot(model_train.history['acc'])\n",
    "#plt.plot(model_train.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'var'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_train.history['loss'])\n",
    "plt.plot(model_train.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'var'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Test Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"../input/diabetic-retinopathy-resized/resized_train/resized_train/\" + val.iloc[0].image_name)\n",
    "im = np.array(im.resize((224, )*2, resample=Image.LANCZOS))\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "testimage = cv2.resize(im, (224,224))\n",
    "testimage = cv2.addWeighted(image,4,cv2.GaussianBlur(image,(0,0),10) ,-4 ,128) \n",
    "\n",
    "print(\"predicted:\", np.argmax(model.predict(testimage.reshape(1, *im.shape))[0]))\n",
    "print(\"actual:\", val.iloc[0].level)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
